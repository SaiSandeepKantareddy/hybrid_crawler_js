# hybrid-crawler-js

A minimal, scalable crawler with conditional JavaScript rendering â€” built to balance coverage and cost at web scale.

## ğŸš€ What It Does

This crawler intelligently decides **when to run JavaScript rendering** (e.g. via Playwright) based on metadata like page structure, script density, and content sparsity.

Instead of rendering every page (which is expensive), it:
- Fetches HTML fast using `aiohttp`
- Scores each page for "JS-needed-ness" using simple heuristics
- Triggers JS rendering only when needed
- Tracks metrics: coverage uplift, rendering rate, cost per page

## ğŸ”§ Tech Stack

- `aiohttp` â€“ for async HTML fetching  
- `Playwright` â€“ headless JS rendering on demand  
- `BeautifulSoup` / `lxml` â€“ for HTML parsing  
- `pandas`, `tqdm` â€“ for metrics and logging

## ğŸ—ï¸ Folder Structure

```
hybrid_crawler_js/
â”œâ”€â”€ crawler/           # Base fetcher, JS renderer, heuristics
â”œâ”€â”€ pipeline/          # Main orchestration and config
â”œâ”€â”€ utils/             # Logging and metrics
â”œâ”€â”€ tests/             # Test scripts
â”œâ”€â”€ data/              # Sample URLs and output
â”œâ”€â”€ requirements.txt   # Dependencies
â””â”€â”€ README.md          # Project documentation
```

## ğŸ§ª Example Use Case

Crawl 10M pages. Only 20% need JS rendering.  
You save **80% infra cost** and still capture **all meaningful content**.

## ğŸ“ˆ Coming Soon

- Coverage vs cost graphs
- A/B test harness
- Real-world benchmarks on public URL datasets

## ğŸ™Œ Inspired By

Andrew Chanâ€™s blazing-fast crawler @ https://andrewkchan.dev/posts/crawler.html  
This builds on that idea to add **intelligent hybrid parsing.**

---

Contributions and suggestions welcome!
